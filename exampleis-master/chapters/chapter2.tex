%!TEX root = ../username.tex
\chapter{Background on Automated Theorem Proving}

\section{Decidability, Incompleteness, and First Order Logic}
\subsection{Decidability}
In order to understand automated theorem proving (ATP) and some of the difficulties faced by it, we will first discuss decidability. Decidability, as the name implies, describes the ability of a claim to be proven. Note that this is not describing the truth value that would be returned after being proven -- it describes if the question can even be proven. 

Decidability features heavily in computational theory. Problems can be loosely divided into two categories, decidable and undecidable, with the decidable category further divided into P and NP. While further distinctions exist, we will not focus on them here. It is important to note that a problem may take billions of years to solve, but it remains decidable -- at the end of the time period, a truth value will be returned for the claim. Undecidable claims can be given unlimited computing power and unlimited time, but will still be unable to return a truth value.

The typical example of an undecidable problem is what is known as the halting problem. This problem seeks to create a program which, when passed another program as input, will determine if the input program will ever cease execution (halt). While this program may seem possible to create, it is not.

\begin{proof}
Let us consider a program \textit{h} which determines if a program passed to it will halt. Let us consider a second program, \textit{p} which takes \textit{h} as an input and passes itself to \textit{h}. This program is then able to see the output of \textit{h}, as \textit{h} will return its value for reading by \textit{p}. From this, \textit{p} reads this input, and performs the opposite of what was predicted by \textit{h}. If it was predicted to halt, it will run forever, and if it was predicted to run forever, it will halt. As \textit{p} uses its knowledge of what \textit{h} will return to determine its behaviour, there is no way for \textit{h} to properly predict the behaviour, and thus no program \textit{h} is possible. \cite{haltProof}
\end{proof}

\subsection{Incompleteness and First Order Logic}
This worry of decidability relates to mathematics through G\"odel's incompleteness theorem. Put simply, the theorem states that ``no consistent system of axioms whose theorems can be listed by an algorithm is capable of proving all truths about the arithmetic of the natural numbers '' \cite{Godel}. Though this formulation limits the theorem to the natural numbers, this is true of any system defined by axioms. What this means is that a set of axioms within a system will not be sufficient to prove consistency within the system, where consistency means that a statement and its negation cannot both be proven from the axioms.

Knowing this about incompleteness and decidability, we now examine the language of automated theorem provers -- first order logic. First order logic is a system used in linguistics, mathematics, computer science, and philosophy in order to logically describe claims and statements. For example, rather than state ``The person reading this sentence understands English'' we instead state ``There exists X such that X is reading sentence Y and X understands English''. The ``first'' indicates that the statements made utilize variables, such as X in the previous sentence, but functions are not used as arguments. First order logic dictates the axiomatization of mathematics. This project uses first order logic axioms for each of the question domains, such as set theory or algebraic arithmetic, in order to define the systems concisely.

As first order logic produces systems which cannot be proven fully based on their axioms, we give a program a set of axioms which may or may not be able to prove our claim, and this program may or may not ever halt. With this in mind, we can see why a system could not simply be allowed to work undisturbed for years to verify a claim. While a theorem prover will be able to become more efficient over time, there will always be problems which cannot be proven just from the axioms for a system.

\section{Historical Development}

While the main additions to mathematics from computational development previously came from automation of basic operational calculations, new potentials arose in the 1950s. With artificial intelligence beginning to be developed, the first attempts were made to automate reasoning, and mathematical understanding along with it.

In 1908, French mathematician Henri Poincar\`e stated that, were formalism of mathematical proof to gain further traction ``one could imagine a machine where one would put in axioms at one end while getting theorems at the other end.'' This was not an idea Poincar\`e was happy with however, with many mathematicians in this period finding the idea of removing the intuition of the mathematician from proving to be disturbing.

This mechanical idea became most clear in 1937, with Turing's description of the Turing Machine, which he used to determine if mathematics is decidable. He determined mathematics to be undecidable, but nonetheless started mathematics down the path of automated theorem proving. Following years of development primarily on automating arithmetic, automated theorem proving began to appear as a question in computing with early attempts to create artificial intelligence.

Allen Newell and Herbert Simon met at the Rand Corporation in 1952. Simon held a PhD in political science, focusing on thought processes, and was intrigued by the idea of using computers to simulate human problem solving. Newell, on the other hand, wanted to use computers to play chess games. In 1955, the two decided to work together, but decided that building a chess playing AI was far too difficult, so picked what they saw as a much easier task -- building an automated theorem prover.

Newell and Simon went on to create the Logic Theory Machine, based on the propositional calculus described in Russell and Whitehad's \textit{Principia}. Propositional calculus is logic which entirely relates to truth and falsity of statements and argument flow, meaning it is significantly simpler than the first order logic which has been discussed up until now. The machine proved the majority of the theorems discussed in \textit{Principia}, even finding a simpler proof than the authors in one case, but this was refused publishing by the \textit{Journal of Symbolic Logic}, as the Logic Theory Machine was considered a co-author. Though an impressive first attempt, Newell and Simon's machine was capable of only very short proofs, as it made no attempts to choose the proper path, and instead took every option available to it.

This early work into automated theorem proving divided academia into two camps -- the logicists and proceduralists. Logicists argued for a system using purely logic based inferences, and were also known as ``neats'' as they did not want the actual details of problems dirtying the logic. Rather than work from an understanding of the input material, a logicist's prover would look only at the underlying predicate logic. If the logic was deemed valid, the claim would be considered to be verified. The proceduralists, or ``scruffies,'' instead believed that knowledge should be considered procedural, rather than axiomatic. The example given by one such proceduralist was that of checking to see if it was safe to cross the road. This, like a proof, will return a truth value. However, it does not seem correct to use the logicist's method in this case. A better understanding of the task is to check each direction, and if no car is seen, consider the road safe to cross. As the proceduralist states, the logicist would be left attempting to prove that no car was coming using logic, rather than this procedure! \cite{ATP History}



\section{Vampire}

Vampire is a first order theorem prover which started development in the late 1990s at the University of Manchester. The system takes input in \textit{Thousands of Problems for Thousands of Provers} (TPTP) format, with the user providing a file which contains axioms based on the domain of the problem, as well as a single conjecture at the end of the file.

First, Vampire takes the conjecture given by the user and negates it. For example, if it had been given a statement of the form ``p and q implies r'', it would convert it to ``p and q and ~r'' before performing further analysis. Following this, Vampire then uses the provided axioms to attempt to find a counter-example to the new claim. In the event that a counter-example is found, the original claim will be true. If in the time Vampire is given to run no counter-example can be found, it is not necessarily the case that the original claim is false. Vampire may also find that the negated claim is logically valid with the axioms, in which case the original claim was false.

Over the past two decades, Vampire has won many awards at the CADE ATP System Competition's top division, winning first in 1999 and then every year from 2001-2010.
