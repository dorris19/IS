%!TEX root = ../username.tex
\chapter{Background on Automated Theorem Proving}

\section{Decidability, Incompleteness, and First Order Logic}
\subsection{Decidability}
In order to understand automated theorem proving (ATP) and some of the difficulties faced by it, we will first discuss decidability. Decidability, as the name implies, describes the ability of a claim to be proven. Note that this is not describing the truth value that would be returned after being proven -- it describes if the question can even be proven. 

Decidability features heavily in computational theory. Problems can be loosely divided into two categories, decidable and undecidable, with the decidable category further divided into P and NP. While further distinctions exist, we will not focus on them here. It is important to note that while an NP problem may take billions of years to solve, it remains decidable -- at the end of the time period, a truth value will be returned for the claim. Undecidable claims can be given infinite computing power and infinite time, but will still be unable to return a truth value.

The typical example of an undecidable problem is what is known as the halting problem. This problem seeks to create a program which, when passed a function, will determine if that program will ever halt, or cease execution. While this program may seem possible to create, it is not.

\begin{proof}
Let us consider a program \textit{h} which determines if a program passed to it will halt. Let us consider a second program, \textit{p} which takes \textit{h} as an input and passes itself to \textit{h}. This program is then able to see the output of \textit{h}, as \textit{h} will return its value for reading by \textit{p}. From this, \textit{p} reads this input, and performs the opposite of what was predicted by \textit{h}. If it was predicted to halt, it will run forever, and if it was predicted to run forever, it will halt. As \textit{p} uses its knowledge of what \textit{h} will return to determine its behaviour, there is no way for \textit{h} to properly predict the behaviour, and thus no program \textit{h} is possible.
\end{proof}

\subsection{Incompleteness and First Order Logic}
This worry of decidability relates to mathematics through G\"odel's incompleteness theorem. Put simply, the theorem states that ``no consistent system of axioms whose theorems can be listed by an algorithm is capable of proving all truths about the arithmetic of the natural numbers '' \cite{Godel}. Though this formulation limits the theorem to the natural numbers, this is true of any system defined by axioms. What this means is that a set of axioms within a system will not be sufficient to prove consistency within the system, where consistency means that a statement and its negation cannot both be proven from the axioms.

Knowing this about incompleteness and decidability, we now examine the language of automated theorem provers -- first order logic. First order logic is a system used in linguistics, mathematics, computer science, and philosophy in order to logically describe claims and statements. For example, rather than state ``The person reading this sentence understands English'' we instead state ``There exists X such that X is reading sentence Y and X understands English''. The ``first'' indicates that the statements made utilize variables, such as X in the previous sentence, but functions are not used as arguments. First order logic dictates the axiomatization of mathematics. This project uses first order logic axioms for each of the question domains, such as set theory or algebraic arithmetic, in order to define the systems concisely.

As first order logic produces systems which cannot be proven fully based on their axioms, we give a program a set of axioms which may or may not be able to prove our claim, and this program may or may not ever halt. With this in mind, we can see why a system could not simply be allowed to work undisturbed for years to verify a claim. While a theorem prover will be able to become more efficient over time, there will always be problems which cannot be proven just from the axioms for a system.

\section{Historical Development}

While the main additions to mathematics from computational development previously came from automation of basic operational calculations, in the 1950s new potentials arose. With artificial intelligence beginning to be developed, the first attempts were made to automate reasoning, and mathematical understanding along with it.

\textbf{Insert more background here}

This early work into automated theorem proving divided academia into two camps -- the logicists and proceduralists. Logicists argued for a system using purely logic based inferences, and were also known as ``neats'' as they did not want the actual details of problems dirtying the logic. Rather than work from an understanding of the input material, a logicist's prover would look only at the underlying predicate logic. If the logic was deemed valid, the claim would be considered to be verified. The proceduralists, or ``scruffies'', instead believed that knowledge should be considered procedural, rather than axiomatic. The example given by one such proceduralist was that of checking to see if it was safe to cross the road. This, like a proof, will return a truth value. However, it does not seem correct to use the logicist's method in this case. A better understanding of the task is to check each direction, and if no car is seen, consider the road safe to cross. As the proceduralist states, the logicist would be left attempting to prove that no car was coming using logic, rather than this procedure!



\section{Vampire}

